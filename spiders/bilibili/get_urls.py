import asyncio
import sys
from playwright.async_api import async_playwright
import re


class BilibiliUrlCollector:
    def __init__(self, use_existing_browser=True, debug_port=9222):
        """
        åˆå§‹åŒ–Bç«™URLæ”¶é›†å™¨

        å‚æ•°ï¼š
            use_existing_browser: æ˜¯å¦è¿æ¥åˆ°ç°æœ‰æµè§ˆå™¨å®ä¾‹
            debug_port: è°ƒè¯•ç«¯å£å·
        """
        self.browser = None
        self.page = None
        self.playwright = None
        self.use_existing_browser = use_existing_browser
        self.debug_port = debug_port

    async def setup_browser(self):
        """è®¾ç½®æµè§ˆå™¨è¿æ¥"""
        if self.playwright is None:
            self.playwright = await async_playwright().start()
        
        if self.use_existing_browser:
            # è¿æ¥åˆ°ç°æœ‰æµè§ˆå™¨å®ä¾‹
            print(f"ğŸ”— å°è¯•è¿æ¥åˆ°ç°æœ‰æµè§ˆå™¨ (ç«¯å£: {self.debug_port})")
            try:
                self.browser = await self.playwright.chromium.connect_over_cdp(f"http://localhost:{self.debug_port}")
                
                # è·å–ç°æœ‰é¡µé¢æˆ–åˆ›å»ºæ–°é¡µé¢
                contexts = self.browser.contexts
                if contexts:
                    pages = contexts[0].pages
                    if pages:
                        # ä½¿ç”¨ç°æœ‰çš„ç¬¬ä¸€ä¸ªé¡µé¢
                        self.page = pages[0]
                        print("âœ… ä½¿ç”¨ç°æœ‰æµè§ˆå™¨é¡µé¢")
                    else:
                        # åœ¨ç°æœ‰ä¸Šä¸‹æ–‡ä¸­åˆ›å»ºæ–°é¡µé¢
                        self.page = await contexts[0].new_page()
                        print("âœ… åœ¨ç°æœ‰æµè§ˆå™¨ä¸­åˆ›å»ºæ–°é¡µé¢")
                else:
                    # åˆ›å»ºæ–°ä¸Šä¸‹æ–‡å’Œé¡µé¢
                    context = await self.browser.new_context()
                    self.page = await context.new_page()
                    print("âœ… åœ¨ç°æœ‰æµè§ˆå™¨ä¸­åˆ›å»ºæ–°ä¸Šä¸‹æ–‡å’Œé¡µé¢")
                    
                print("ğŸ‰ æˆåŠŸè¿æ¥åˆ°ç°æœ‰æµè§ˆå™¨ï¼")
                
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¿æ¥åˆ°ç°æœ‰æµè§ˆå™¨: {e}")
                print("ğŸ’¡ è¯·å…ˆå¯åŠ¨Chromeæµè§ˆå™¨å¹¶å¼€å¯è°ƒè¯•æ¨¡å¼ï¼š")
                print(f"   /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port={self.debug_port} --user-data-dir=/tmp/chrome-debug")
                raise Exception("æ— æ³•è¿æ¥åˆ°ç°æœ‰æµè§ˆå™¨ï¼Œè¯·å…ˆæŒ‰ç…§ä¸Šè¿°è¯´æ˜å¯åŠ¨Chrome")
        else:
            # å¯åŠ¨æ–°çš„æµè§ˆå™¨å®ä¾‹
            print("ğŸš€ å¯åŠ¨æ–°çš„æµè§ˆå™¨å®ä¾‹...")
            self.browser = await self.playwright.chromium.launch(headless=False)
            context = await self.browser.new_context()
            self.page = await context.new_page()

    async def navigate_to_page(self, base_url, page_number):
        """
        é€šè¿‡æµè§ˆå™¨æ“ä½œè·³è½¬åˆ°æŒ‡å®šé¡µç ï¼ˆçº¯æ“ä½œå¼ï¼Œä¸ä¿®æ”¹URLï¼‰
        
        å‚æ•°ï¼š
            base_url: åŸºç¡€URL
            page_number: é¡µç 
        è¿”å›ï¼š
            æ˜¯å¦è·³è½¬æˆåŠŸ
        """
        print(f"ğŸ”„ é€šè¿‡è¾“å…¥æ¡†è·³è½¬åˆ°ç¬¬ {page_number} é¡µ")
        
        try:
            # å¦‚æœæ˜¯ç¬¬ä¸€é¡µï¼Œç›´æ¥è®¿é—®åŸºç¡€URL
            if page_number == 1:
                await self.page.goto(base_url, wait_until="domcontentloaded", timeout=30000)
                await self.page.wait_for_timeout(3000)
                print(f"âœ… æˆåŠŸè®¿é—®ç¬¬ 1 é¡µ")
                return True
            
            # ç¡®ä¿æˆ‘ä»¬åœ¨æ­£ç¡®çš„é¡µé¢ä¸Š
            current_url = self.page.url
            base_domain = base_url.split('?')[0]
            if not current_url.startswith(base_domain):
                print(f"ğŸ“± é¦–å…ˆè®¿é—®åŸºç¡€é¡µé¢ï¼š{base_url}")
                await self.page.goto(base_url, wait_until="domcontentloaded", timeout=30000)
                await self.page.wait_for_timeout(3000)
            
            # æŸ¥æ‰¾é¡µç è¾“å…¥æ¡†
            input_xpath = '//*[@id="app"]/main/div[1]/div[2]/div/div[3]/div/div[2]/div/div/input'
            
            print(f"ğŸ” æŸ¥æ‰¾é¡µç è¾“å…¥æ¡†...")
            
            # ç­‰å¾…è¾“å…¥æ¡†å‡ºç°
            try:
                await self.page.wait_for_selector(f"xpath={input_xpath}", timeout=10000)
                print(f"âœ… æ‰¾åˆ°é¡µç è¾“å…¥æ¡†")
                
                # è·å–è¾“å…¥æ¡†å…ƒç´ 
                input_element = await self.page.query_selector(f"xpath={input_xpath}")
                
                if input_element:
                    # æ£€æŸ¥è¾“å…¥æ¡†æ˜¯å¦å¯è§å’Œå¯æ“ä½œ
                    is_visible = await input_element.is_visible()
                    is_enabled = await input_element.is_enabled()
                    
                    print(f"ğŸ“‹ è¾“å…¥æ¡†çŠ¶æ€ - å¯è§: {is_visible}, å¯ç”¨: {is_enabled}")
                    
                    if not is_visible or not is_enabled:
                        print(f"âš ï¸ è¾“å…¥æ¡†ä¸å¯æ“ä½œï¼Œå°è¯•æ»šåŠ¨åˆ°å¯è§åŒºåŸŸ")
                        await input_element.scroll_into_view_if_needed()
                        await self.page.wait_for_timeout(1000)
                    
                    # ç‚¹å‡»è¾“å…¥æ¡†ä»¥è·å¾—ç„¦ç‚¹
                    print(f"ğŸ‘† ç‚¹å‡»è¾“å…¥æ¡†")
                    await input_element.click()
                    await self.page.wait_for_timeout(500)
                    
                    # å…¨é€‰å¹¶æ¸…ç©ºè¾“å…¥æ¡†å†…å®¹
                    print(f"ğŸ—‘ï¸ æ¸…ç©ºè¾“å…¥æ¡†å†…å®¹")
                    await input_element.select_text()
                    await self.page.wait_for_timeout(200)
                    
                    # è¾“å…¥ç›®æ ‡é¡µç 
                    print(f"âŒ¨ï¸ è¾“å…¥é¡µç : {page_number}")
                    await input_element.type(str(page_number), delay=100)
                    await self.page.wait_for_timeout(500)
                    
                    # éªŒè¯è¾“å…¥æ˜¯å¦æ­£ç¡®
                    input_value = await input_element.input_value()
                    print(f"ğŸ“ è¾“å…¥æ¡†å½“å‰å€¼: '{input_value}'")
                    
                    if str(page_number) not in input_value:
                        print(f"âš ï¸ è¾“å…¥å€¼ä¸æ­£ç¡®ï¼Œé‡è¯•...")
                        await input_element.fill(str(page_number))
                        await self.page.wait_for_timeout(500)
                    
                    # æŒ‰å›è½¦é”®ç¡®è®¤è·³è½¬
                    print(f"â æŒ‰ä¸‹å›è½¦é”®")
                    await input_element.press("Enter")
                    
                    # ç­‰å¾…é¡µé¢è·³è½¬
                    print(f"â³ ç­‰å¾…é¡µé¢è·³è½¬...")
                    await self.page.wait_for_timeout(4000)
                    
                    # éªŒè¯é¡µé¢æ˜¯å¦æˆåŠŸè·³è½¬
                    success = await self.verify_page_navigation(page_number)
                    if success:
                        print(f"âœ… æˆåŠŸè·³è½¬åˆ°ç¬¬ {page_number} é¡µ")
                        return True
                    else:
                        print(f"âŒ è·³è½¬åˆ°ç¬¬ {page_number} é¡µå¤±è´¥")
                        return False
                        
                else:
                    print(f"âŒ æ— æ³•è·å–è¾“å…¥æ¡†å…ƒç´ ")
                    return False
                    
            except Exception as e:
                print(f"âŒ æ“ä½œé¡µç è¾“å…¥æ¡†æ—¶å‡ºé”™ï¼š{e}")
                # å°è¯•å…¶ä»–å¯èƒ½çš„è¾“å…¥æ¡†é€‰æ‹©å™¨
                return await self.try_alternative_input_methods(page_number)
            
        except Exception as e:
            print(f"âŒ è·³è½¬åˆ°ç¬¬ {page_number} é¡µæ—¶å‡ºé”™ï¼š{e}")
            return False

    async def try_alternative_input_methods(self, page_number):
        """
        å°è¯•å…¶ä»–å¯èƒ½çš„è¾“å…¥æ¡†å®šä½æ–¹æ³•
        """
        print(f"ğŸ”„ å°è¯•å…¶ä»–è¾“å…¥æ¡†å®šä½æ–¹æ³•...")
        
        alternative_selectors = [
            'input[type="text"][placeholder*="é¡µ"]',
            'input[type="number"]',
            '.be-pager input',
            '.bili-pagination input',
            'input.page-input',
            '.pagination input'
        ]
        
        for selector in alternative_selectors:
            try:
                print(f"ğŸ” å°è¯•é€‰æ‹©å™¨: {selector}")
                element = await self.page.query_selector(selector)
                if element:
                    is_visible = await element.is_visible()
                    if is_visible:
                        print(f"âœ… æ‰¾åˆ°å¯ç”¨çš„è¾“å…¥æ¡†: {selector}")
                        
                        # æ‰§è¡Œè¾“å…¥æ“ä½œ
                        await element.click()
                        await self.page.wait_for_timeout(500)
                        await element.select_text()
                        await element.type(str(page_number), delay=100)
                        await element.press("Enter")
                        await self.page.wait_for_timeout(4000)
                        
                        # éªŒè¯è·³è½¬
                        success = await self.verify_page_navigation(page_number)
                        if success:
                            print(f"âœ… é€šè¿‡å¤‡ç”¨æ–¹æ³•æˆåŠŸè·³è½¬åˆ°ç¬¬ {page_number} é¡µ")
                            return True
                            
            except Exception as e:
                print(f"âš ï¸ å¤‡ç”¨é€‰æ‹©å™¨ {selector} å¤±è´¥: {e}")
                continue
        
        print(f"âŒ æ‰€æœ‰è¾“å…¥æ¡†å®šä½æ–¹æ³•éƒ½å¤±è´¥äº†")
        return False

    # ç§»é™¤å¤‡ç”¨URLè·³è½¬æ–¹æ³•ï¼Œç¡®ä¿åªä½¿ç”¨æ“ä½œå¼è·³è½¬

    async def verify_page_navigation(self, expected_page):
        """
        éªŒè¯é¡µé¢æ˜¯å¦æˆåŠŸè·³è½¬åˆ°æŒ‡å®šé¡µç 
        """
        try:
            # é¦–å…ˆæ£€æŸ¥è¾“å…¥æ¡†ä¸­çš„å€¼
            input_xpath = '//*[@id="app"]/main/div[1]/div[2]/div/div[3]/div/div[2]/div/div/input'
            try:
                input_element = await self.page.query_selector(f"xpath={input_xpath}")
                if input_element:
                    input_value = await input_element.get_attribute('value')
                    if input_value and str(expected_page) == input_value.strip():
                        print(f"âœ… è¾“å…¥æ¡†æ˜¾ç¤ºé¡µç ï¼š{input_value}")
                        return True
            except:
                pass
            
            # æ£€æŸ¥URLä¸­çš„é¡µç å‚æ•°
            current_url = self.page.url
            if f"pn={expected_page}" in current_url:
                print(f"âœ… URLä¸­åŒ…å«é¡µç å‚æ•°ï¼špn={expected_page}")
                return True
            
            # å°è¯•æŸ¥æ‰¾é¡µç æŒ‡ç¤ºå™¨çš„å¤šç§å¯èƒ½é€‰æ‹©å™¨
            page_indicators = [
                f'.be-pager-item[title="{expected_page}"]',
                f'.bili-pagination__item[title="{expected_page}"]',
                f'[data-page="{expected_page}"]',
                '.be-pager-item--current',
                '.bili-pagination__item--current',
                '.be-pager-item.be-pager-item-active',
                '.current-page'
            ]
            
            for selector in page_indicators:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        text = await element.text_content()
                        if text and str(expected_page) in text.strip():
                            print(f"âœ… æ‰¾åˆ°é¡µç æŒ‡ç¤ºå™¨ï¼š{text.strip()}")
                            return True
                except:
                    continue
            
            # æ£€æŸ¥é¡µé¢å†…å®¹æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ˆä½œä¸ºæœ€åçš„éªŒè¯æ‰‹æ®µï¼‰
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘å†…å®¹
                video_selectors = [
                    'a[href*="/video/BV"]',
                    '.video-card',
                    '.bili-video-card'
                ]
                
                for selector in video_selectors:
                    elements = await self.page.query_selector_all(selector)
                    if len(elements) > 0:
                        print(f"âœ… é¡µé¢åŒ…å« {len(elements)} ä¸ªè§†é¢‘å…ƒç´ ï¼Œå‡è®¾è·³è½¬æˆåŠŸ")
                        return True
            except:
                pass
            
            print(f"âš ï¸ æ— æ³•ç¡®è®¤æ˜¯å¦æˆåŠŸè·³è½¬åˆ°ç¬¬ {expected_page} é¡µï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            return True  # å‡è®¾æˆåŠŸï¼Œç»§ç»­æ‰§è¡Œ
            
        except Exception as e:
            print(f"âš ï¸ éªŒè¯é¡µé¢è·³è½¬æ—¶å‡ºé”™ï¼š{e}")
            return True

    async def get_video_urls_with_pagination(self, base_url, page_numbers, xpath=None):
        """
        è·å–å¤šä¸ªé¡µé¢çš„è§†é¢‘URL
        
        å‚æ•°ï¼š
            base_url: åŸºç¡€URL
            page_numbers: é¡µç åˆ—è¡¨
            xpath: ç”¨äºå®šä½è§†é¢‘é“¾æ¥çš„XPathè¡¨è¾¾å¼
        è¿”å›ï¼š
            æ‰€æœ‰é¡µé¢çš„è§†é¢‘URLåˆ—è¡¨
        """
        if xpath is None:
            xpath = '//*[@id="app"]/main/div[1]/div[2]/div/div[2]/div/div/div/div/div/div/div[2]/div[1]/a'
        
        all_video_urls = set()
        
        try:
            await self.setup_browser()
            
            # è®¾ç½®ç”¨æˆ·ä»£ç†
            await self.page.set_extra_http_headers({
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            })
            
            for i, page_num in enumerate(page_numbers, 1):
                print(f"\nğŸ“„ å¤„ç†ç¬¬ {page_num} é¡µ ({i}/{len(page_numbers)})")
                
                # è·³è½¬åˆ°æŒ‡å®šé¡µé¢
                success = await self.navigate_to_page(base_url, page_num)
                if not success:
                    print(f"âŒ è·³è½¬åˆ°ç¬¬ {page_num} é¡µå¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # å°è¯•æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹
                await self.scroll_to_load_content()
                
                # ä½¿ç”¨XPathæŸ¥æ‰¾æ‰€æœ‰è§†é¢‘é“¾æ¥
                print(f"ğŸ” åœ¨ç¬¬ {page_num} é¡µæŸ¥æ‰¾è§†é¢‘é“¾æ¥")
                
                # æå–å½“å‰é¡µé¢çš„è§†é¢‘URL
                page_video_urls = await self.extract_video_urls_multiple_strategies(xpath)
                
                # æ·»åŠ åˆ°æ€»é›†åˆä¸­
                page_urls_count = len(page_video_urls)
                new_urls_count = len(set(page_video_urls) - all_video_urls)
                all_video_urls.update(page_video_urls)
                
                print(f"âœ… ç¬¬ {page_num} é¡µæ‰¾åˆ° {page_urls_count} ä¸ªURLï¼Œå…¶ä¸­ {new_urls_count} ä¸ªæ˜¯æ–°çš„")
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€é¡µï¼Œç­‰å¾…ä¸€ä¸‹å†å¤„ç†ä¸‹ä¸€é¡µ
                if i < len(page_numbers):
                    print("â³ ç­‰å¾…2ç§’åå¤„ç†ä¸‹ä¸€é¡µ...")
                    await self.page.wait_for_timeout(2000)
            
            return list(all_video_urls)
            
        except Exception as e:
            print(f"âŒ è·å–å¤šé¡µé¢è§†é¢‘URLæ—¶å‡ºé”™ï¼š{e}")
            return list(all_video_urls)

    async def get_video_urls(self, page_url, xpath=None):
        """
        è·å–å•ä¸ªé¡µé¢ä¸Šæ‰€æœ‰è§†é¢‘çš„URL (åŸç‰ˆæ–¹æ³•)

        å‚æ•°ï¼š
            page_url: è¦æŠ“å–çš„é¡µé¢URL
            xpath: ç”¨äºå®šä½è§†é¢‘é“¾æ¥çš„XPathè¡¨è¾¾å¼
        è¿”å›ï¼š
            è§†é¢‘URLåˆ—è¡¨
        """
        if xpath is None:
            xpath = '//*[@id="app"]/main/div[1]/div[2]/div/div[2]/div/div/div/div/div/div/div[2]/div[1]/a'
        
        try:
            await self.setup_browser()
            
            # è®¾ç½®ç”¨æˆ·ä»£ç†
            await self.page.set_extra_http_headers({
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            })
            
            print(f"ğŸ“± æ­£åœ¨è®¿é—®é¡µé¢ï¼š{page_url}")
            await self.page.goto(page_url, wait_until="domcontentloaded", timeout=30000)
            
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            await self.page.wait_for_timeout(3000)
            
            # å°è¯•æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹
            await self.scroll_to_load_content()
            
            # ä½¿ç”¨XPathæŸ¥æ‰¾æ‰€æœ‰è§†é¢‘é“¾æ¥
            print(f"ğŸ” ä½¿ç”¨XPathæŸ¥æ‰¾è§†é¢‘é“¾æ¥ï¼š{xpath}")
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨ç­–ç•¥
            video_urls = await self.extract_video_urls_multiple_strategies(xpath)
            
            return video_urls
            
        except Exception as e:
            print(f"âŒ è·å–è§†é¢‘URLæ—¶å‡ºé”™ï¼š{e}")
            return []
        """
        è·å–é¡µé¢ä¸Šæ‰€æœ‰è§†é¢‘çš„URL

        å‚æ•°ï¼š
            page_url: è¦æŠ“å–çš„é¡µé¢URL
            xpath: ç”¨äºå®šä½è§†é¢‘é“¾æ¥çš„XPathè¡¨è¾¾å¼
        è¿”å›ï¼š
            è§†é¢‘URLåˆ—è¡¨
        """
        if xpath is None:
            xpath = '//*[@id="app"]/main/div[1]/div[2]/div/div[2]/div/div/div/div/div/div/div[2]/div[1]/a'
        
        try:
            await self.setup_browser()
            
            # è®¾ç½®ç”¨æˆ·ä»£ç†
            await self.page.set_extra_http_headers({
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            })
            
            print(f"ğŸ“± æ­£åœ¨è®¿é—®é¡µé¢ï¼š{page_url}")
            await self.page.goto(page_url, wait_until="domcontentloaded", timeout=30000)
            
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            await self.page.wait_for_timeout(3000)
            
            # å°è¯•æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹
            await self.scroll_to_load_content()
            
            # ä½¿ç”¨XPathæŸ¥æ‰¾æ‰€æœ‰è§†é¢‘é“¾æ¥
            print(f"ğŸ” ä½¿ç”¨XPathæŸ¥æ‰¾è§†é¢‘é“¾æ¥ï¼š{xpath}")
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨ç­–ç•¥
            video_urls = await self.extract_video_urls_multiple_strategies(xpath)
            
            return video_urls
            
        except Exception as e:
            print(f"âŒ è·å–è§†é¢‘URLæ—¶å‡ºé”™ï¼š{e}")
            return []

    async def extract_video_urls_multiple_strategies(self, primary_xpath):
        """
        ä½¿ç”¨å¤šç§ç­–ç•¥æå–è§†é¢‘URL
        """
        video_urls = set()
        
        # ç­–ç•¥1: ä½¿ç”¨æä¾›çš„XPath
        try:
            elements = await self.page.locator(f"xpath={primary_xpath}").all()
            for element in elements:
                href = await element.get_attribute('href')
                if href:
                    full_url = self.normalize_bilibili_url(href)
                    if full_url:
                        video_urls.add(full_url)
            print(f"âœ… ç­–ç•¥1 (XPath) æ‰¾åˆ° {len(video_urls)} ä¸ªURL")
        except Exception as e:
            print(f"âš ï¸ ç­–ç•¥1 (XPath) å¤±è´¥: {e}")
        
        # ç­–ç•¥2: é€šç”¨CSSé€‰æ‹©å™¨
        try:
            css_selectors = [
                'a[href*="/video/BV"]',
                'a[href*="bilibili.com/video"]',
                '.video-card a',
                '.bili-video-card a',
                '.card-box a'
            ]
            
            for selector in css_selectors:
                elements = await self.page.locator(selector).all()
                for element in elements:
                    href = await element.get_attribute('href')
                    if href:
                        full_url = self.normalize_bilibili_url(href)
                        if full_url:
                            video_urls.add(full_url)
            
            print(f"âœ… ç­–ç•¥2 (CSSé€‰æ‹©å™¨) æ€»å…±æ‰¾åˆ° {len(video_urls)} ä¸ªå”¯ä¸€URL")
        except Exception as e:
            print(f"âš ï¸ ç­–ç•¥2 (CSSé€‰æ‹©å™¨) å¤±è´¥: {e}")
        
        # ç­–ç•¥3: æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…é¡µé¢å†…å®¹
        try:
            page_content = await self.page.content()
            bv_pattern = r'(?:https?://)?(?:www\.)?bilibili\.com/video/(BV[0-9A-Za-z]{10})'
            matches = re.findall(bv_pattern, page_content)
            
            for bv in set(matches):
                full_url = f"https://www.bilibili.com/video/{bv}"
                video_urls.add(full_url)
            
            print(f"âœ… ç­–ç•¥3 (æ­£åˆ™è¡¨è¾¾å¼) æ€»å…±æ‰¾åˆ° {len(video_urls)} ä¸ªå”¯ä¸€URL")
        except Exception as e:
            print(f"âš ï¸ ç­–ç•¥3 (æ­£åˆ™è¡¨è¾¾å¼) å¤±è´¥: {e}")
        
        return list(video_urls)

    def normalize_bilibili_url(self, href):
        """
        æ ‡å‡†åŒ–Bç«™è§†é¢‘URL
        """
        if not href:
            return None
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè¡¥å…¨åŸŸå
        if href.startswith('/'):
            href = f"https://www.bilibili.com{href}"
        elif href.startswith('//'):
            href = f"https:{href}"
        
        # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„Bç«™è§†é¢‘URL
        bv_pattern = r'BV[0-9A-Za-z]{10}'
        if re.search(bv_pattern, href):
            # æå–BVå·å¹¶æ„é€ æ ‡å‡†URL
            match = re.search(bv_pattern, href)
            if match:
                bv = match.group(0)
                return f"https://www.bilibili.com/video/{bv}"
        
        return None

    async def scroll_to_load_content(self):
        """
        æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹
        """
        try:
            print("ğŸ“œ æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹...")
            
            # è·å–é¡µé¢é«˜åº¦
            last_height = await self.page.evaluate("document.body.scrollHeight")
            
            scroll_attempts = 0
            max_scrolls = 5  # æœ€å¤šæ»šåŠ¨5æ¬¡
            
            while scroll_attempts < max_scrolls:
                # æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
                await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                
                # ç­‰å¾…æ–°å†…å®¹åŠ è½½
                await self.page.wait_for_timeout(2000)
                
                # è·å–æ–°çš„é¡µé¢é«˜åº¦
                new_height = await self.page.evaluate("document.body.scrollHeight")
                
                # å¦‚æœé«˜åº¦æ²¡æœ‰å˜åŒ–ï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šå†…å®¹äº†
                if new_height == last_height:
                    break
                
                last_height = new_height
                scroll_attempts += 1
                print(f"   ğŸ“œ æ»šåŠ¨ {scroll_attempts}/{max_scrolls} æ¬¡")
            
            # æ»šåŠ¨å›é¡¶éƒ¨
            await self.page.evaluate("window.scrollTo(0, 0)")
            await self.page.wait_for_timeout(1000)
            
        except Exception as e:
            print(f"âš ï¸ æ»šåŠ¨é¡µé¢æ—¶å‡ºé”™: {e}")

    async def close(self):
        """å…³é—­æµè§ˆå™¨è¿æ¥"""
        try:
            if not self.use_existing_browser and self.browser:
                await self.browser.close()
                print("ğŸ”’ æ–°å»ºçš„æµè§ˆå™¨å®ä¾‹å·²å…³é—­")
            elif self.use_existing_browser:
                print("ğŸ”— ä¿æŒç°æœ‰æµè§ˆå™¨è¿æ¥")
            
            if self.playwright:
                await self.playwright.stop()
                print("ğŸ­ Playwrightè¿æ¥å·²æ–­å¼€")
        except Exception as e:
            print(f"âš ï¸ å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™ï¼š{e}")


async def collect_urls_multi_page(base_url, page_numbers, xpath=None):
    """
    æ”¶é›†å¤šä¸ªé¡µé¢ä¸Šçš„æ‰€æœ‰è§†é¢‘URL
    
    å‚æ•°ï¼š
        base_url: åŸºç¡€é¡µé¢URL
        page_numbers: é¡µç åˆ—è¡¨
        xpath: å¯é€‰çš„XPathè¡¨è¾¾å¼
    """
    collector = BilibiliUrlCollector(use_existing_browser=True, debug_port=9222)
    
    try:
        video_urls = await collector.get_video_urls_with_pagination(base_url, page_numbers, xpath)
        
        if video_urls:
            print(f"\nğŸ‰ æ€»å…±æ‰¾åˆ° {len(video_urls)} ä¸ªå”¯ä¸€è§†é¢‘URL:")
            
            # è¾“å‡ºé€—å·åˆ†éš”çš„URL
            urls_string = ','.join(video_urls)
            print(f"\nğŸ“‹ é€—å·åˆ†éš”çš„URLåˆ—è¡¨:")
            print(urls_string)
            
            # åŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶
            with open('video_urls.txt', 'w', encoding='utf-8') as f:
                f.write(urls_string)
            print(f"\nğŸ’¾ URLåˆ—è¡¨å·²ä¿å­˜åˆ° video_urls.txt")
            
            return video_urls
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘URL")
            return []
            
    except Exception as e:
        print(f"âŒ æ”¶é›†URLæ—¶å‡ºé”™ï¼š{e}")
        return []
    
    finally:
        await collector.close()


async def collect_urls(page_url, xpath=None):
    """
    æ”¶é›†é¡µé¢ä¸Šçš„æ‰€æœ‰è§†é¢‘URL (åŸæœ‰çš„å•é¡µé¢ç‰ˆæœ¬)
    
    å‚æ•°ï¼š
        page_url: è¦æŠ“å–çš„é¡µé¢URL
        xpath: å¯é€‰çš„XPathè¡¨è¾¾å¼
    """
    collector = BilibiliUrlCollector(use_existing_browser=True, debug_port=9222)
    
    try:
        video_urls = await collector.get_video_urls(page_url, xpath)
        
        if video_urls:
            print(f"\nğŸ‰ æˆåŠŸæ‰¾åˆ° {len(video_urls)} ä¸ªè§†é¢‘URL:")
            
            # è¾“å‡ºé€—å·åˆ†éš”çš„URL
            urls_string = ','.join(video_urls)
            print(f"\nğŸ“‹ é€—å·åˆ†éš”çš„URLåˆ—è¡¨:")
            print(urls_string)
            
            # åŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶
            with open('video_urls.txt', 'w', encoding='utf-8') as f:
                f.write(urls_string)
            print(f"\nğŸ’¾ URLåˆ—è¡¨å·²ä¿å­˜åˆ° video_urls.txt")
            
            return video_urls
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘URL")
            return []
            
    except Exception as e:
        print(f"âŒ æ”¶é›†URLæ—¶å‡ºé”™ï¼š{e}")
        return []
    
    finally:
        await collector.close()


def parse_page_input(page_input):
    """
    è§£æé¡µç è¾“å…¥
    
    å‚æ•°ï¼š
        page_input: é¡µç è¾“å…¥å­—ç¬¦ä¸²ï¼Œæ”¯æŒæ ¼å¼å¦‚ "1", "1,3,5", "1-5"
    è¿”å›ï¼š
        é¡µç åˆ—è¡¨
    """
    page_numbers = []
    
    try:
        # å¤„ç†é€—å·åˆ†éš”çš„é¡µç 
        parts = page_input.split(',')
        
        for part in parts:
            part = part.strip()
            
            # å¤„ç†èŒƒå›´æ ¼å¼ (å¦‚ "1-5")
            if '-' in part:
                start, end = part.split('-')
                start_num = int(start.strip())
                end_num = int(end.strip())
                page_numbers.extend(range(start_num, end_num + 1))
            else:
                # å•ä¸ªé¡µç 
                page_numbers.append(int(part))
        
        # å»é‡å¹¶æ’åº
        page_numbers = sorted(list(set(page_numbers)))
        
    except ValueError as e:
        print(f"âŒ é¡µç æ ¼å¼é”™è¯¯ï¼š{e}")
        return []
    
    return page_numbers


def interactive_main():
    """äº¤äº’å¼ä¸»å‡½æ•°"""
    print("ğŸ¯ === Bç«™è§†é¢‘URLæ”¶é›†å·¥å…· (äº¤äº’å¼) ===")
    print("\nğŸ’¡ è¯·ç¡®ä¿Chromeæµè§ˆå™¨å·²å¼€å¯è°ƒè¯•æ¨¡å¼ï¼š")
    print("   /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222")
    
    # è·å–åŸºç¡€URL
    base_url = input("\nğŸ“„ è¯·è¾“å…¥åŸºç¡€é¡µé¢URL (å¦‚: https://space.bilibili.com/123456/video): ").strip()
    if not base_url:
        print("âŒ URLä¸èƒ½ä¸ºç©º")
        return
    
    # è·å–é¡µç 
    print("\nğŸ“‹ é¡µç è¾“å…¥æ ¼å¼è¯´æ˜:")
    print("   å•é¡µ: 1")
    print("   å¤šé¡µ: 1,3,5")
    print("   èŒƒå›´: 1-5")
    print("   æ··åˆ: 1,3-5,8")
    
    page_input = input("\nğŸ“„ è¯·è¾“å…¥è¦æŠ“å–çš„é¡µç : ").strip()
    if not page_input:
        print("âŒ é¡µç ä¸èƒ½ä¸ºç©º")
        return
    
    # è§£æé¡µç 
    page_numbers = parse_page_input(page_input)
    if not page_numbers:
        print("âŒ é¡µç è§£æå¤±è´¥")
        return
    
    # å¯é€‰çš„è‡ªå®šä¹‰XPath
    custom_xpath = input("\nğŸ¯ è¯·è¾“å…¥è‡ªå®šä¹‰XPath (å¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
    xpath = custom_xpath if custom_xpath else None
    
    print(f"\nğŸ“Š ä»»åŠ¡æ¦‚è§ˆ:")
    print(f"   ğŸ”— åŸºç¡€URL: {base_url}")
    print(f"   ğŸ“„ é¡µç : {page_numbers}")
    print(f"   ğŸ¯ XPath: {xpath or 'ä½¿ç”¨é»˜è®¤'}")
    
    confirm = input("\nâ“ ç¡®è®¤å¼€å§‹æŠ“å–? (y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("âŒ ä»»åŠ¡å·²å–æ¶ˆ")
        return
    
    print("\nğŸ”„ å¼€å§‹æ”¶é›†URL...\n")
    
    # è¿è¡Œå¼‚æ­¥ä»»åŠ¡ - ä½¿ç”¨çº¯æ“ä½œå¼è·³è½¬
    if len(page_numbers) == 1:
        # å•é¡µé¢å¤„ç†ï¼Œä¹Ÿä½¿ç”¨æ“ä½œå¼è·³è½¬
        asyncio.run(collect_urls_multi_page(base_url, page_numbers, xpath))
    else:
        # å¤šé¡µé¢å¤„ç†
        asyncio.run(collect_urls_multi_page(base_url, page_numbers, xpath))


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) == 1:
        # æ²¡æœ‰å‚æ•°ï¼Œä½¿ç”¨äº¤äº’å¼æ¨¡å¼
        interactive_main()
    elif len(sys.argv) >= 2:
        # æœ‰å‚æ•°ï¼Œä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼
        if sys.argv[1] in ['-h', '--help', 'help']:
            print_help()
            return
        
        page_url = sys.argv[1]
        xpath = sys.argv[2] if len(sys.argv) > 2 else None
        
        print("ğŸ¯ === Bç«™è§†é¢‘URLæ”¶é›†å·¥å…· (å‘½ä»¤è¡Œæ¨¡å¼) ===")
        print(f"ğŸ“„ ç›®æ ‡é¡µé¢ï¼š{page_url}")
        if xpath:
            print(f"ğŸ¯ ä½¿ç”¨XPathï¼š{xpath}")
        
        print("\nğŸ’¡ è¯·ç¡®ä¿Chromeæµè§ˆå™¨å·²å¼€å¯è°ƒè¯•æ¨¡å¼ï¼š")
        print("   /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222")
        print("\nğŸ”„ å¼€å§‹æ”¶é›†URL...\n")
        
        # è¿è¡Œå¼‚æ­¥ä»»åŠ¡ - æå–é¡µç å¹¶ä½¿ç”¨æ“ä½œå¼è·³è½¬
        # ä»URLä¸­æå–é¡µç 
        page_number = 1
        if 'pn=' in page_url:
            import urllib.parse as urlparse
            parsed = urlparse.urlparse(page_url)
            params = urlparse.parse_qs(parsed.query)
            if 'pn' in params:
                try:
                    page_number = int(params['pn'][0])
                except:
                    page_number = 1
        
        # è·å–åŸºç¡€URLï¼ˆå»æ‰é¡µç å‚æ•°ï¼‰
        base_url = page_url.split('?')[0] if '?' in page_url else page_url
        
        # ä½¿ç”¨æ“ä½œå¼è·³è½¬
        asyncio.run(collect_urls_multi_page(base_url, [page_number], xpath))


def print_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("ğŸ¯ === Bç«™è§†é¢‘URLæ”¶é›†å·¥å…· ===")
    print("\nğŸ“– ä½¿ç”¨æ–¹æ³•:")
    print("  äº¤äº’å¼æ¨¡å¼:")
    print("    python get_urls.py")
    print("    ç„¶åæŒ‰æç¤ºè¾“å…¥URLå’Œé¡µç ")
    print("\n  å‘½ä»¤è¡Œæ¨¡å¼:")
    print("    python get_urls.py <page_url> [xpath]")
    print("\nğŸ“‹ ç¤ºä¾‹:")
    print("  äº¤äº’å¼:")
    print("    python get_urls.py")
    print("\n  å‘½ä»¤è¡Œ:")
    print('    python get_urls.py "https://space.bilibili.com/123456/video"')
    print('    python get_urls.py "https://space.bilibili.com/123456/video" "//*[@id=\'app\']/main/div[1]/div[2]/div/div[2]/div/div/div/div/div/div/div[2]/div[1]/a"')
    print("\nğŸ¯ é¡µç æ ¼å¼è¯´æ˜ (ä»…äº¤äº’å¼æ¨¡å¼):")
    print("    å•é¡µ: 1")
    print("    å¤šé¡µ: 1,3,5")
    print("    èŒƒå›´: 1-5")
    print("    æ··åˆ: 1,3-5,8")
    print("\nğŸ’¡ ä½¿ç”¨å‰è¯·ç¡®ä¿Chromeæµè§ˆå™¨å·²å¼€å¯è°ƒè¯•æ¨¡å¼ï¼š")
    print("    /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222")


if __name__ == "__main__":
    main()
